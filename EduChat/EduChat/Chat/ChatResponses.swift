import Foundation

struct ChatResponses {
    // 일반 모드용 하드코딩된 응답들
    static let normalMode: [String: String] = [
        "퍼셉트론": """
퍼셉트론은 인공지능의 가장 기본적인 구성 요소예요! 🤖🧠

간단히 말하면, 퍼셉트론은 우리 뇌의 신경세포를 본떠 만든 수학적 모델이에요. 여러 입력을 받아서 가중치를 곱하고, 최종적으로 YES 또는 NO 같은 결정을 내리는 거죠.

예를 들어, 날씨가 맑고 기온이 적당하며 예약이 되어 있다면 식당 입장을 허용하는 것처럼 작동해요. 각 요소에 점수를 매겨서 임계값을 넘으면 입장을 허용하는 방식이죠!

퍼셉트론의 핵심은 '학습'이에요. 틀린 예측을 할 때마다 스스로 가중치를 조정해서 점점 더 정확해지는 거예요. 마치 학생이 시험에서 틀린 문제를 분석해서 다음번엔 더 잘 풀려고 노력하는 것과 비슷해요.

실제로 이메일 스팸 분류나 센서 데이터 분석 같은 간단한 분류 문제에 많이 사용돼요. 복잡한 문제는 다층 퍼셉트론이나 신경망으로 해결하지만, 퍼셉트론은 여전히 AI의 기초 개념으로 중요합니다!
""",

        "신경망": """
신경망은 퍼셉트론을 여러 층으로 쌓아서 만든 고급 AI 모델이에요! 🧠🔗

기본 아이디어는 간단해요: 하나의 퍼셉트론이 처리하기 어려운 복잡한 문제를, 여러 개의 퍼셉트론을 연결해서 해결하는 거예요. 마치 회사에서 부장-과장-대리처럼 계층적으로 일을 분담하는 것과 비슷하죠!

각 층마다 다른 역할을 해요:
• 입력층: 원본 데이터를 받아들임
• 은닉층: 복잡한 패턴을 학습하고 추출
• 출력층: 최종 결정을 내림

신경망의 장점은 스스로 학습한다는 점이에요. 백프로퍼게이션이라는 알고리즘으로 오류를 뒤로 전파하면서 가중치를 조정하죠.

실제로 이미지 인식, 자연어 처리, 추천 시스템 등 다양한 분야에서 활약하고 있어요. 딥러닝의 기반이 되는 기술이죠!
""",

        "딥러닝": """
딥러닝은 신경망을 아주 깊게 쌓아서 만든 최첨단 AI 기술이에요! 🏗️🤖

'딥'은 '깊은'이라는 뜻으로, 수십에서 수백 개의 층으로 이루어진 신경망을 의미해요. 각 층마다 점점 더 추상화된 특징을 학습하죠.

예를 들어 사진을 분석할 때:
• 첫 번째 층: 선과 모서리 감지
• 중간 층: 형태와 패턴 인식
• 마지막 층: "이건 고양이야!"라고 판단

딥러닝의 핵심은 대량의 데이터와 강력한 컴퓨터로 스스로 학습한다는 점이에요. 인간이 일일이 규칙을 만들지 않아도 되죠!

실제로 음성인식, 자율주행, 의료진단 등 혁신적인 분야에서 사용되고 있어요. AI 발전의 핵심 동력이에요!
""",

        "인공신경망": """
인공신경망(ANN)은 생물학적 신경계를 모방한 컴퓨터 프로그램이에요! 🧬💻

우리 뇌의 신경세포(뉴런)를 수학적으로 모델링한 거예요. 각 뉴런은:
1. 여러 입력을 받음
2. 가중치를 곱해서 합산
3. 활성화 함수로 출력 결정

이런 뉴런들이 서로 연결되어 복잡한 네트워크를 형성하죠. 마치 뇌의 시냅스처럼 정보를 전달하고 처리하는 거예요!

인공신경망은 스스로 학습해요. 데이터를 보면서 연결 강도(가중치)를 자동으로 조정하죠. 이 과정이 바로 '기계학습'이에요.

실제로 패턴인식, 예측, 분류 등 다양한 문제에 적용돼요. 딥러닝의 기초가 되는 중요한 개념입니다!
""",

        "선형대수학": """
선형대수학은 벡터와 행렬을 다루는 수학 분야예요! 🔢📐

AI와 데이터 과학의 핵심 도구로, 다음과 같은 개념들이 중요해요:

**벡터**: 방향과 크기를 가진 화살표 같은 개념. 데이터 포인트를 표현할 때 사용
**행렬**: 벡터를 여러 개 모아둔 사각형 배열. 데이터 변환에 필수적
**텐서**: 다차원 배열로, 딥러닝에서 데이터를 표현하는 기본 단위

선형대수학은 데이터를 효율적으로 처리하고 변환하는 방법을 제공해요. 행렬 연산으로 수백만 개의 계산을 동시에 수행할 수 있죠!

실제로 신경망의 가중치 계산, 데이터 압축, 차원 축소 등 AI의 모든 곳에서 사용돼요. AI를 이해하려면 선형대수학이 필수예요!
"""
    ]

    // 딥러닝 모드용 심층 분석 응답들
    static let deepLearningMode: [String: String] = [
        "퍼셉트론": """
퍼셉트론은 인공지능의 가장 기본적인 구성 요소예요! 🤖🧠

간단히 말하면, 퍼셉트론은 우리 뇌의 신경세포를 본떠 만든 수학적 모델이에요. 여러 입력을 받아서 가중치를 곱하고, 최종적으로 YES 또는 NO 같은 결정을 내리는 거죠.

예를 들어, 날씨가 맑고 기온이 적당하며 예약이 되어 있다면 식당 입장을 허용하는 것처럼 작동해요. 각 요소에 점수를 매겨서 임계값을 넘으면 입장을 허용하는 방식이죠!

퍼셉트론의 핵심은 '학습'이에요. 틀린 예측을 할 때마다 스스로 가중치를 조정해서 점점 더 정확해지는 거예요. 마치 학생이 시험에서 틀린 문제를 분석해서 다음번엔 더 잘 풀려고 노력하는 것과 비슷해요.

실제로 이메일 스팸 분류나 센서 데이터 분석 같은 간단한 분류 문제에 많이 사용돼요. 복잡한 문제는 다층 퍼셉트론이나 신경망으로 해결하지만, 퍼셉트론은 여전히 AI의 기초 개념으로 중요합니다!

역사적으로 1957년에 처음 제안되었고, AI 발전의 출발점이 되었어요. 한계는 있었지만, 그 한계가 오히려 더 발전된 기술들을 탄생시키는 계기가 되었죠.
""",

        "신경망": """
신경망은 퍼셉트론을 여러 층으로 쌓아서 만든 고급 AI 모델이에요! 🧠🔗

기본 아이디어는 간단해요: 하나의 퍼셉트론이 처리하기 어려운 복잡한 문제를, 여러 개의 퍼셉트론을 연결해서 해결하는 거예요. 마치 회사에서 부장-과장-대리처럼 계층적으로 일을 분담하는 것과 비슷하죠!

각 층마다 다른 역할을 해요:
• 입력층: 원본 데이터를 받아들임
• 은닉층: 복잡한 패턴을 학습하고 추출
• 출력층: 최종 결정을 내림

신경망의 장점은 스스로 학습한다는 점이에요. 백프로퍼게이션이라는 알고리즘으로 오류를 뒤로 전파하면서 가중치를 조정하죠.

실제로 이미지 인식, 자연어 처리, 추천 시스템 등 다양한 분야에서 활약하고 있어요. 딥러닝의 기반이 되는 기술이죠!

신경망은 1960년대에 처음 등장했지만, 컴퓨터 성능 부족으로 한동안 잊혀졌다가 1980년대 백프로퍼게이션 알고리즘 발견으로 다시 부활했어요. 그 후 딥러닝 혁명의 토대가 되었죠.
""",

        "딥러닝": """
딥러닝은 신경망을 아주 깊게 쌓아서 만든 최첨단 AI 기술이에요! 🏗️🤖

'딥'은 '깊은'이라는 뜻으로, 수십에서 수백 개의 층으로 이루어진 신경망을 의미해요. 각 층마다 점점 더 추상화된 특징을 학습하죠.

예를 들어 사진을 분석할 때:
• 첫 번째 층: 선과 모서리 감지
• 중간 층: 형태와 패턴 인식
• 마지막 층: "이건 고양이야!"라고 판단

딥러닝의 핵심은 대량의 데이터와 강력한 컴퓨터로 스스로 학습한다는 점이에요. 인간이 일일이 규칙을 만들지 않아도 되죠!

실제로 음성인식, 자율주행, 의료진단 등 혁신적인 분야에서 사용되고 있어요. AI 발전의 핵심 동력이에요!

딥러닝은 2010년대 초반에 GPU의 발전과 빅데이터의 등장으로 급격히 발전했어요. 알렉스넷이 이미지넷 대회에서 압도적인 성능을 보여주면서 딥러닝 시대가 열렸죠.
""",

        "인공신경망": """
인공신경망(ANN)은 생물학적 신경계를 모방한 컴퓨터 프로그램이에요! 🧬💻

우리 뇌의 신경세포(뉴런)를 수학적으로 모델링한 거예요. 각 뉴런은:
1. 여러 입력을 받음
2. 가중치를 곱해서 합산
3. 활성화 함수로 출력 결정

이런 뉴런들이 서로 연결되어 복잡한 네트워크를 형성하죠. 마치 뇌의 시냅스처럼 정보를 전달하고 처리하는 거예요!

인공신경망은 스스로 학습해요. 데이터를 보면서 연결 강도(가중치)를 자동으로 조정하죠. 이 과정이 바로 '기계학습'이에요.

실제로 패턴인식, 예측, 분류 등 다양한 문제에 적용돼요. 딥러닝의 기초가 되는 중요한 개념입니다!

인공신경망은 1943년 매컬러와 피츠의 연구에서 시작되었어요. 1950년대 퍼셉트론이 등장했고, 1980년대 다층 퍼셉트론으로 발전했죠. 오늘날 AI의 핵심 기술이 되었어요.
""",

        "선형대수학": """
선형대수학은 벡터와 행렬을 다루는 수학 분야예요! 🔢📐

AI와 데이터 과학의 핵심 도구로, 다음과 같은 개념들이 중요해요:

**벡터**: 방향과 크기를 가진 화살표 같은 개념. 데이터 포인트를 표현할 때 사용
**행렬**: 벡터를 여러 개 모아둔 사각형 배열. 데이터 변환에 필수적
**텐서**: 다차원 배열로, 딥러닝에서 데이터를 표현하는 기본 단위

선형대수학은 데이터를 효율적으로 처리하고 변환하는 방법을 제공해요. 행렬 연산으로 수백만 개의 계산을 동시에 수행할 수 있죠!

실제로 신경망의 가중치 계산, 데이터 압축, 차원 축소 등 AI의 모든 곳에서 사용돼요. AI를 이해하려면 선형대수학이 필수예요!

선형대수학은 19세기에 시작되었지만, 컴퓨터의 등장으로 새로운 응용 분야를 찾았어요. 특히 1950년대부터 컴퓨터 과학과 결합되면서 AI 발전의 수학적 기반이 되었죠.
"""
    ]
}
